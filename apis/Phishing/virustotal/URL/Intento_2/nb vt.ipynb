{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -----------------------------\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "VT_BASE = \"https://www.virustotal.com/api/v3\"\n",
    "API_KEY = os.environ.get(\"VT_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise RuntimeError(\"VT_API_KEY no definida. Exporta tu API key en la variable de entorno VT_API_KEY.\")\n",
    "\n",
    "HEADERS = {\"accept\": \"application/json\", \"x-apikey\": API_KEY}\n",
    "\n",
    "# -----------------------------\n",
    "# Leer archivo desde AWS S3 y obtener lista de URLs\n",
    "url1 = \"https://desafiogrupo1.s3.us-east-1.amazonaws.com/phishing.json\"\n",
    "df1 = pd.read_json(url1)\n",
    "df1.info()\n",
    "\n",
    "# Lista de URLs limpia\n",
    "urls = df1['url'].dropna().tolist()\n",
    "print(f\"Total URLs: {len(urls)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Orden de keys para reproducibilidad\n",
    "URL_KEYS_ORDER = [\"url\", \"last_analysis_stats\", \"status\", \"network_location\"]\n",
    "NETWORK_LOCATION_KEYS_ORDER = [\n",
    "    \"whois\", \"tags\", \"last_dns_records\", \"popularity_ranks\", \"last_analysis_date\",\n",
    "    \"last_https_certificate\", \"last_analysis_stats\", \"last_dns_records_date\",\n",
    "    \"last_modification_date\", \"registrar\", \"reputation\", \"expiration_date\",\n",
    "    \"tld\", \"last_https_certificate_date\", \"jarm\", \"categories\"\n",
    "]\n",
    "\n",
    "NETLOC_FIELDS_DEFAULTS = {\n",
    "    \"whois\": \"\",\n",
    "    \"tags\": [],\n",
    "    \"last_dns_records\": [],\n",
    "    \"popularity_ranks\": {},\n",
    "    \"last_https_certificate\": {},\n",
    "    \"last_analysis_stats\": {},\n",
    "    \"categories\": {}\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Funciones auxiliares\n",
    "def _remove_key_recursive(obj, key_to_remove=\"last_analysis_results\"):\n",
    "    if isinstance(obj, dict):\n",
    "        if key_to_remove in obj:\n",
    "            obj.pop(key_to_remove)\n",
    "        for v in obj.values():\n",
    "            _remove_key_recursive(v, key_to_remove)\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            _remove_key_recursive(item, key_to_remove)\n",
    "\n",
    "def _ordered_network_location(netloc_attrs):\n",
    "    netloc_out = OrderedDict()\n",
    "    for k in NETWORK_LOCATION_KEYS_ORDER:\n",
    "        netloc_out[k] = netloc_attrs.get(k, NETLOC_FIELDS_DEFAULTS.get(k))\n",
    "    _remove_key_recursive(netloc_out, \"last_analysis_results\")\n",
    "    return netloc_out\n",
    "\n",
    "def _ordered_url_object(url_result):\n",
    "    od = OrderedDict()\n",
    "    for k in URL_KEYS_ORDER:\n",
    "        if k == \"network_location\" and url_result.get(\"network_location\"):\n",
    "            od[k] = _ordered_network_location(url_result[\"network_location\"])\n",
    "        else:\n",
    "            od[k] = url_result.get(k)\n",
    "    return od\n",
    "\n",
    "# -----------------------------\n",
    "# Función principal para consultar VT\n",
    "def get_url_info(url, retries=2, timeout=10, pause_between_calls=1.0):\n",
    "    url_id = base64.urlsafe_b64encode(url.encode()).decode().strip(\"=\")\n",
    "    result = {\"url\": url}\n",
    "\n",
    "    # 1) /urls/{url_id}\n",
    "    for attempt in range(retries+1):\n",
    "        try:\n",
    "            resp = requests.get(f\"{VT_BASE}/urls/{url_id}\", headers=HEADERS, timeout=timeout)\n",
    "            if resp.status_code == 404:\n",
    "                result[\"status\"] = \"URL NO REPORTADA\"\n",
    "                return _ordered_url_object(result)\n",
    "            if resp.status_code == 401:\n",
    "                result[\"status\"] = \"ERROR_AUTH\"\n",
    "                result[\"error\"] = \"401 Unauthorized - revisa tu API key.\"\n",
    "                return _ordered_url_object(result)\n",
    "            resp.raise_for_status()\n",
    "            attrs = resp.json().get(\"data\", {}).get(\"attributes\", {}) or {}\n",
    "            result[\"last_analysis_stats\"] = attrs.get(\"last_analysis_stats\", {\n",
    "                \"malicious\": 0, \"suspicious\": 0, \"undetected\": 0, \"harmless\": 0, \"timeout\": 0\n",
    "            })\n",
    "            result[\"status\"] = \"OK\"\n",
    "            break\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < retries:\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                result[\"status\"] = \"ERROR\"\n",
    "                result[\"error_url_object\"] = str(e)\n",
    "                return _ordered_url_object(result)\n",
    "\n",
    "    time.sleep(pause_between_calls)\n",
    "\n",
    "    # 2) network_location\n",
    "    try:\n",
    "        netloc_resp = requests.get(f\"{VT_BASE}/urls/{url_id}/network_location\", headers=HEADERS, timeout=timeout)\n",
    "        if netloc_resp.status_code == 404:\n",
    "            return _ordered_url_object(result)\n",
    "        netloc_resp.raise_for_status()\n",
    "        netloc_data_ref = netloc_resp.json().get(\"data\", {}) or {}\n",
    "        # attributes embebidos\n",
    "        netloc_attrs = netloc_data_ref.get(\"attributes\", {}) or {}\n",
    "        result[\"network_location\"] = netloc_attrs\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        result[\"network_location\"] = {}\n",
    "        result[\"_error_network_location\"] = str(e)\n",
    "\n",
    "    return _ordered_url_object(result)\n",
    "\n",
    "# -----------------------------\n",
    "# Ejecutar para todas las URLs del archivo\n",
    "resultados = []\n",
    "for i, u in enumerate(urls):\n",
    "    print(f\"[{i+1}/{len(urls)}] consultando {u} ...\")\n",
    "    r = get_url_info(u, retries=2, timeout=15, pause_between_calls=1.0)\n",
    "    resultados.append(r)\n",
    "    time.sleep(2)  # pausa prudente para no saturar la API\n",
    "\n",
    "# -----------------------------\n",
    "# Guardar JSON con keys en orden exacto\n",
    "with open(\"resultados_vt_full.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, indent=4, ensure_ascii=False, sort_keys=False)\n",
    "\n",
    "# CSV plano por si quieren inspección rápida\n",
    "df_out = pd.json_normalize(resultados)\n",
    "df_out.to_csv(\"resultados_vt_full.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Listo: resultados_vt_full.json y resultados_vt_full.csv creados.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
